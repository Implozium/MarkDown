Микрофронтенды
==============

**Микрофронтенд** - это концепция, которая распространяет принципы архитектуры микросервисов на мир фронтенда - фронтенд-приложения декомпозируют на части, которые можно разрабатывать, тестировать и развертывать независимо друг от друга.

Разбиение происходит по такой логике:
- каждый микрофронтенд отвечает за отдельную функцию или область приложения;
- микрофронтенды объединяют в целостный пользовательский опыт.

Основные преимущества микрофронтендов:
- **повышение организационной гибкости**, что позволяет различным командам работать параллельно, не завися друг от друга при развертывании;
- **можно использовать несколько технологических стеков** в зависимости от задач;
- **упрощение управления кодом**, так как каждая команда управляет только тем кодом, который относится к ее функциональности, что значительно облегчает сопровождение: обновление или исправление одного раздела не вызовет непредвиденных последствий в других частях приложения;
- **более управляемое масштабирование** из-за того, что каждый микрофронтенд развернут независимо от остальных;
- **повышение отказоустойчивости**, так как изоляция микрофронтендов повышает общую устойчивость приложения и в случае отказа микрофронтенда откажет только этот микрофронтенд;
- **ускорение времени выхода на рынок**  из-за того, что дает возможность разрабатывать, тестировать и внедрять обновления мелкими порциями, что позволяет больше экспериментировать и оперативно реагировать на изменения рынка.

Основные компоненты:
- **модули микрофронтенда** - это основные элементы архитектуры. Каждый модуль - это определенная бизнес-область или функциональность. Модули разрабатывают, тестируют и развертывают независимо друг от друга;
- **слой композиции** - отвечает за сборку различных модулей микрофронтенда в целостное приложение, а также управляет потоком данных и взаимодействием между клиентом и сервером. Компоновка модулей может происходить на стороне сервера, на стороне клиента или с помощью гибридного подхода;
- **маршрутизация** - отвечает за то, что запросы будут направляться к нужному микрофронтенду, что помогает сохранить модульность приложения (независимость микрофронтендов друг от друга) и при этом обеспечить плавную навигацию для пользователей;
- **коммуникационный слой** - управляет взаимодействием между микрофронтендами и остальной инфраструктурой приложения посредством API, шины сообщений или собственных систем событий.

## Стратегии проектирования микрофронтендов

### Стратегия вертикальной нарезки

**Стратегия вертикальной нарезки** основана на *предметно-ориентированном проектировании* (Domain-Driven Design, DDD), что предполагает, что приложение делится на **домены** (domain) - предметные области, которые описывают разные цели бизнеса.

Суть вертикальной нарезки в том, чтобы спроектировать каждый микрофронтенд как самодостаточную систему, которая соответствует отдельной бизнес-функции. Тогда он будет включать всю необходимую внешнюю логику: от пользовательского интерфейса до уровня получения данных, который относится к его области.

Плюсы:
- каждый микрофронтенд предоставляет полный набор функций, который можно разрабатывать, тестировать и развертывать независимо от других;
- снижает зависимость между командами;
- упрощает управление проектами и масштабирование.

Минусы:
- тяжело определить границы каждого домена, так как на это влияет бизнес и тщательное планирование разработки.

Использование:
- когда есть **сложные пользовательские интерфейсы**, которые обслуживают разные бизнес-функции;
- когда есть **кросс-функциональные команды** вокруг бизнес-возможностей или клиентских путей, а не технологических стеков.

### Стратегия автономность команд

**Стратегия автономность команд** основана на том, что каждая команда имеет возможность выбрать технологический стек, который подходит под ее задачи и использовать сильные стороны технологий, чтобы достичь оптимальной производительности и удобства работы пользователей.

Плюсы:
- способствует росту инноваций;
- помогает создавать более адаптированные технические решения;
- ускоряет разработку и улучшает качество продукта.

Минусы:
- может привести к фрагментации и трудностям в управлении сквозными проблемами (стилизацией, доступностью и общей согласованностью пользовательского опыта).

Использование:
- когда есть **разные технологические потребности** из-за того, что разные части приложения выиграют от разных технологических стеков;
- когда есть **проекты, ориентированные на инновации и эксперименты**.

### Стратегия изоляции

**Стратегия изоляции** основана на том, что у микрофронтендов нет общих зависимостей во время выполнения. То есть каждый микрофронтенд должен включать все свои зависимости. Они инкапсулируются в пакет развертывания микрофронтенда. Общие библиотеки в микрофронтендах будут дублироваться, но их можно совместить с помощью стратегического управления версиями на более широком уровне. Изоляция необходима, чтобы избежать конфликтов версий и облегчить обновление или замену отдельных микрофронтендов.

Плюсы:
- снижается риск того, что изменения в одном микрофронтенде повлияют на другие;
- упрощается обновление и сопровождение, так как не нужно подстраиваться под все приложение.

Минусы:
- общие библиотеки включены в несколько микрофронтендов, и из-за этого размер приложения увеличится.

Использование:
- когда есть **частые обновления и развертывания** в средах, где микрофронтенды должны обновляться часто и независимо друг от друга. Это гарантирует, что обновления не помешают друг другу;
- когда нужно **независимо масштабировать разные части приложения** у которых разные нагрузки и требования к производительности.

## Методы интеграции микрофронтендов

**Build time** - это объединение во время сборки - когда все компоненты помещаюся в контейнер. Мало отличается от монолитного фреймворка так как:
- нужно синхронизировать разные версии библиотек, иначе возникнут проблемы со сборкой;
- сложно использовать разные технологии;
- конечный бандл получится большим, ведь он содержит все зависимости;
- при появлении изменений в зависимостях, придется развертывать пакет заново;
- между контейнером и микрофронтендами будет тесная связь.

Подходит:
- когда нужно **упростить развертывание**, так как интеграция во время сборки ориентирована на единый механизм развертывания и единый исходный код, что дает на выходе единый пакет для развертывания;
- когда нужно **оставить тесное взаимодействие функций**, так как микрофронтенды тесно интегрированы с общими зависимостями;
- когда нужно **оптимизировать производительность**, так как интеграция во время сборки позволяет использовать разные техники оптимизации (tree-shaking, разделение кода), что способствует повышению производительности.

**Run time** - это объединение во время выполнения исполнения кода на стороне пользователя.

Подходит:
- когда нужно **развертывать модули независимо**, что позволит каждой команде развертывать свои изменения, не затрагивая другие части приложения;
- когда нужно **динамически обновлять отдельные модули** без переразвертывания всего приложения;
- когда нужно **сделать масштабирование гибким**, что позволит масштабировать разные части приложения независимо.

## Методы композиции микрофронтендов

Это процесс сборки нескольких микрофронтендов в единое целое.

**Серверная композиция** - когда все микрофронтенды собирают на сервере. Вся функциональность находится в бэкенде. Он решает, какой микрофронтенд собрать и загрузить. Сервер будет решать, к какому URL направить запрос.

Используется когда важен SEO и быстрый первоначальный отклик.

**Клиентская композиция** - когда браузер отвечает за динамическую загрузку каждого микрофронтенда во время выполнения.

Используется когда много интерактивного контента, который меняется в зависимости от взаимодействия с пользователем.

**Гибридная композиция** - состоит из серверной и клиентской композиции и использует для каждого микрофронтенда свой выделенный бэкенд *Backend for Frontend* (BFF). BFF обрабатывает все данные, взаимодействует с API и при необходимости предоставляет клиенту предварительно отрендеренный HTML. Это полезно для начальной загрузки страниц и SEO. Сервер передает клиенту полностью сформированную страницу.

## Инструменты для создания микрофронтендов

### Module Federation

Это отдельный плагин Webpack.

Module Federation позволяет независимым приложениям использовать общий код во время выполнения. Он основан на функции **lazy loading**, которая позволяет приложению загружать фрагменты кода по требованию, что сокращает время первоначальной загрузки и помогает оптимизировать использование ресурсов.

Есть две роли:
- **хост** (host) - это основное приложение, которое при запуске динамически загружает удаленные модули;
- **удаленный модуль** (remote) - это отдельный микрофронтенд, который предоставляет часть своей функциональности хосту или другим удаленным модулям.

Хост и удаленные модули могут использовать **общие зависимости**, используя функцию **shared dependencies**, которая позволяет эффективно управлять версиями и гарантирует, что приложение загрузит одну версию библиотеки, если это возможно.

### Single SPA

Это JavaScript-фреймворк. Он позволяет использовать несколько JavaScript-фреймворков на одной странице, не обновляя ее целиком. Он предназначен для управления маршрутизацией и координацией между различными микрофронтендами.

Основные особенности:
- **framework agnostic** (независимость от фреймворков) - приложение не зависит от какого-то конкретного фреймворка, поэтому можно поддерживать сразу нескольких фреймворков на одной странице;
- **lazy loading** (ленивая загрузка) - приложение загружает фрагменты кода по требованию, что улучшает время первоначальной загрузки и производительность;
- **независимая развертываемость** - каждый микрофронтенд может быть развернут независимо и из-за этого проще поддерживать большие приложения, над которыми работают несколько команд.

Состоит из:
- **root** (рут, корень) - основное приложение, которое подгружает разные микрофронтенды;
- **микрофронтендов**, которые подключают к руту.

## Стратегии управления состоянием

### Взаимодействие на основе API

Коммуникация на основе API подразумевает, что бэкенд и микрофронтенды взаимодействуют через HTTP-запросы. Для обмена данными используют RESTful или GraphQL API.

Подходит когда:
- **микрофронтенды должны взаимодействовать с бэкендом, а не напрямую друг с другом** - они в основном занимаются получением или обновлением данных из централизованного бэкенда;
- **есть простой обмен данными**, которые нужны только чтобы отобразить их в компоненте или отправить форму;
- **есть высокие требования к производительности и масштабируемости**, так как каждый микрофронтенд самостоятельно получает данные и обновляет свое состояние, что позволяет каждому микрофронтенду обеспечить независимое масштабирование и оптимальную производительность.

### Паттерн Pub/Sub

Используется паттерн проектирования **Pub/Sub**, при котором компоненты системы выступают в роли **издателей** (publisher) или **подписчиков** (subscriber). При таком подходе компоненты не знают о существовании друг друга, они взаимодействуют только с **событиями** - публикуют их или подписываются на них.

**Event Bus** (шина событий) - это система обмена сообщениями, которая основана на паттерне **Pub/Sub**. События публикуются в шине событий. Компоненты-подписчики регистрируются в шине и указывают список событий, которые они хотят получать. Шина событий разделяет микрофронтенды, убирает взаимозависимость и обеспечивает гибкость.

Подходит когда:
- **предпочтительно несвязанное соединение** между микрофронтендами, что позволяет им взаимодействовать без прямых зависимостей, что упрощает добавление, удаление или обновление микрофронтендов;
- **используется архитектура, управляемая событиями** (event-driven architecture, EDA) - действия или обновления в одной части приложения вызывают реакции в других частях и это эффективно для обновлений в реальном времени и асинхронных коммуникаций;
- **есть независимое развертывание**, так как помогает отделить логику взаимодействия от фактической реализации.

### Библиотека глобального состояния

При использовании библиотеки глобального состояния разные микрофронтенды могут получить доступ к общему состоянию и изменять его. Библиотека сама ходит в базу данных через API и обновляет данные на фронтенде.

Этот подход гарантирует, что все части приложения синхронизируются и последовательно взаимодействуют с пользователем.

Подходит когда:
- **есть тесная связь между разными частями приложения** и нужно, чтобы разные части приложения совместно использовали глобальное состояние и информация там всегда была актуальной, так как несколько микрофронтендов читают из одного состояния и записывают в него обновления;
- **важно поддерживать последовательный пользовательский опыт**, это получается благодаря общему состоянию, из-за которого поддерживается единообразие и согласованность в разных частях приложения;
- **есть сложные требования к управлению состояниями** и когда оно вложенное или иерархическое.

## Паттерн Backend for Frontend

**Backend for Frontend** (бэкенд для фронтенда, BFF) - это подход к проектированию, при котором каждый фронтенд обслуживает специальный бэкенд - промежуточный слой между фронтендом и внутренними сервисами, для того чтобы абстрагировать фронтенд от сложностей бэкенда. BFF отвечает за сбор информации от разных микросервисов, ее обработку и доставку на фронтенд в удобном формате.

Используется при архитектурах когда есть:
- **монолитный фронтенд и микросервисы** - для того чтобы абстрагировать фронтенд от сложностей бэкенда;
- **несколько клиентов, которые используют разные технологии для передачи данных** - для того чтобы не усложнять бекенды поддержкой разных технологий;
- **микросервисы и микрофронтенды** - для организации взаимодействие между ними.

Этот подход позволяет:
- **подготавливать данные для конкретного фронтенда**, что снижает необходимость дополнительной обработки данных на стороне клиента;
- **упростить логику на стороне клиента**, так как обрабатывает сложные логические операции на стороне сервера - агрегацию, композицию и преобразованию данных, что снижает сложность кода фронтенда и улучшает его сопровождение;
- **увеличить производительность**, так как передается меньше данных по сети и выполняется меньше запросов из фронтенда;
- **усилить безопасность**, так как запросы пользователей на BFF могут аутентифицироваться и авторизовываться перед передачей внутренним службам.

Микросервисы
============

## Паттерн Strangler Fig

Этот паттерн предлагает итеративный подход к миграции от монолита к микросервисам, когда новую систему постепенно создают по краям старой: компоненты по очереди извлекают из монолита и заменяют на микросервисы. При релизе каждого микросервиса запросы от монолита перенаправляют к новой системе. В итоге бэкенд отмирает по кусочкам, а команда может дорабатывать готовые микросервисы по отзывам пользователей.

Такой подход позволяет постоянно совершенствовать систему и минимизировать риски, которые связаны с большими изменениями.

Основные преимущества:
- **постепенная замена монолита**, что позволяет уменьшить количество сбоев и повысить адаптивность новой системы из-за того, что части монолита заменяются микросервисами итеративно;
- **снижение рисков и управление ими**, так как инкрементные изменения небольшие, то их легче тестировать, отслеживать и откатывать, что уменьшает количество сбоев. Микросервисы запускают параллельно с существующими монолитными компонентами, что позволяет в случае проблем перенаправить запросы обратно на компонент монолита с помощью маршрутизации;
- **инкрементная доставка новых функций в процессе миграции** из-за того, что приложение продолжает развиваться и новые функции и улучшения можно релизить по готовности не дожидаясь окончания миграции;
- **эффективное решение проблемы технического долга**, так как есть систематический рефакторинг вследствие того, что каждый микросервис можно спроектировать и разработать с использованием лучших практик и современных технологий, а также позволит разработать документацию и поддержать стандарты. В первую очередь замена начинается с устаревших компонентов, тогда каждое обновление будет повышать производительность системы и упрощать ее обслуживание.

Шаги по реализации паттерна Strangler Fig:
1. **Определение компонента, который нужно извлечь из монолита** - нужно определить и приоритизировать компоненты монолитного приложения, которые должны быть извлечены. Компонент выбирается с помощью техник:
    - **анализ домена бизнеса** - основан на Domain-Driven Design (DDD) и представляет из себя разделение приложения на домены, которые представляют собой ограниченный контекст бизнес-проблем и целей. Применяется когда монолитное приложение содержит сложную бизнес-логику и поддерживается крупными командами и эта техника помогает структурировать код так, чтобы он лучше отражал бизнес-процессы и был проще в сопровождении и развитии;
    - **технический анализ** - представляет из себя разделение приложения по части кода, который часто меняются или который сложно поддерживать - тесно связанные компоненты, помогает выявить скрытые зависимости и взаимодействия, которые не видны только при бизнес-анализе;
    - **анализ показателей производительности** - представляет из себя разделение приложения по компонентам, вызывающих проблемы с производительностью или требующих больших ресурсов. Применяется в приложениях, которым необходимо эффективное масштабирование.

2. **Проектирование и разработка нового микросервиса** с учетом принципов проектирования:
    - у микросервиса есть единственная, четко определенная зона ответственности;
    - микросервис должен минимально зависить от других сервисов;
    - связанная функциональность должна быть сгруппирована в рамках одного сервиса для поддержания высокой согласованности.

3. **Перенаправление запросов от монолита к микросервису** с помощью:
    - **маршрутизации на основе прокси**:
        - **обратный прокси-сервер**, который будет использоваться для маршрутизации запросов либо к монолиту, либо к новым микросервисам на основе определенных правил;
        - **API-шлюз** - реализуется для управления и маршрутизации трафика, обеспечивая единую точку входа для всех клиентских запросов;
    - **фича-тогглов** - (переключатели функций), которые нужны для управления развертыванием новых функций, чтобы постепенно перенаправлять трафик на новые сервисы;
    - **канареечных релизов**, которые постепенно переводят трафик на новые микросервисы, отслеживая производительность и стабильность перед полным развертыванием.

4. **Внедрения мониторинга и верификаци для микросервиса**. Для оценки производительности и надежности микросервисов используются количественные показатели - **метрики производительности** для каждого микросервиса с пороговым значением уровня производительности:
    - **ключевые показатели эффективности** (Key Performance Indicators, KPI), которые состоят из показателей:
        - времени отклика;
        - частоты ошибок;
        - пропускной способности;
        - количество запросов в секунду.
    - **цели уровня сервиса** (Service-Level Objectives, SLO) - это четко определенные цели в области производительности и доступности сервиса, которые ставятся на основе бизнес-требований, таких как время безотказной работы или время отклика;
    - **индикаторы уровня обслуживания** (Service Level Indicator, SLI) - это количественная оценка работы сервиса, показывающая, выполняются ли SLO, определяются для критических показателей и отслеживаются на соответствие с заданными SLO. К ним относят:
        - латентность - время, необходимое для обработки запроса;
        - доступность - доля времени, в течение которого сервис работает;
        - частота ошибок.

    Для отслеживания производительности, работоспособности и доступности сервисов используются **средства мониторинга**, которые собирают и анализируют данные, чтобы помочь обнаружить проблемы и обеспечить бесперебойную работу служб:
    - **мониторинг производительности приложений** (Application Performance Monitoring, APM), которые отслеживают производительность приложений и отдельных микросервисов в режиме реального времени, предоставляют информацию о времени отклика, количестве ошибок и взаимодействии с пользователями;
    - **централизованное логирование**, которые объединяют журналы различных служб в одном месте, что упрощает поиск, анализ и устранение проблем;
    - **мониторинг инфраструктуры**, которые следят за состоянием и производительностью базовой инфраструктуры (серверы, контейнеры, сетевые компоненты и т.п.).

    Для обеспечивания правильного функционирования новых микросервисов в соответствии с ожидаемым стандартом производительности и надежности используются **методы верификации**:
    - **автоматизированное тестирование** - юнит-тесты, интеграционные тесты, e2e-тесты, которые проверяет функциональность, производительность и интеграцию микросервисов на их соответствие заданным критериям при каждом коммите кода в системе контроля версий;
    - **А/B-тестирование** - для того чтобы сравнивать производительность и влияние на пользователей двух версий сайта, приложения или сервиса, чтобы определить, какая из них работает лучше с помощью перенаправления части запросов на новую версию, а остальную часть - на старую.

5. **Возвращение к шагу 1 до тех пор, пока весь монолит не будет заменен на микросервисы**. Состоит из:
    - **инкрементального извлечения**, которое предполагает разбиение монолитного приложения на более мелкие, управляемые компоненты и постепенную замену их микросервисами;
    - **непрерывного улучшения**, которое направлено на регулярное усовершенствование новых микросервисов с помощью рефакторинга и оптимизации (по мере необходимости) и всей системы в целом, на основе данных о производительности с помощью инструментов APM, анализу обратной связи и меняющихся потребностей бизнеса;
    - **координации работы команды** с помощью сотрудничества между кросс-функциональными командами - разработки, эксплуатации и бизнеса для согласования целей и прогресса, четкой коммуникации с помощью регулярных встреч которые необходимы для обсуждения прогресса, выявления препятствий и планирования следующих шагов, и последовательного документирование на протяжении всего процесса для обеспечения последовательности и обмена знаниями.

Распространенные проблемы:
- **недостаточное планирование** из-за слишком поспешной реализация миграции без четкого плана;
- **отсутствие поддержки заинтересованных сторон** из-за отсутствия понимания предполагаемых рисков;
- **недостаточный мониторинг и тестирование** из-за неспособности адекватно контролировать новые сервисы, что может привести к незамеченным проблемам, влияющим на производительность;
- **игнорирование зависимостей** между компонентами, которые приводят к сбоям или неожиданному поведению;
- **неполная документация** которая может привести к путанице и несогласованным реализациям;
- **игнорирование проблем управления и обмен данными** между монолитом и микросервисами, которые приводят к несогласованности и проблемам целостности данных.

### Методы расстановки приоритетов

#### MoSCoW

Метод приоритизации **MoSCoW** разделяет требования на четыре категории:
- **Must have** (обязательно);
- **Should have** (нужно);
- **Could have** (желательно);
- **Won't have** (можно перенести).

Используется когда у проекта есть четко определенные бизнес-цели, и необходимо тесно увязать технические задачи с приоритетами бизнеса и в процесс вовлечено множество заинтересованных сторон и их согласие крайне важно.

Используется для стратегического планирования.

#### Матрица Эйзенхауэра

**Матрица Эйзенхауэра** - это инструмент управления временем, который помогает расставить приоритеты задач, разделяя их на четыре категории:
- **срочные и важные**;
- **важные, но не срочные**;
- **срочные, но не важные**;
- **не срочные и не важные**.

Используется когда необходимо учитывать срочность задач и где быстрое принятие решений имеет решающее значение.

Используется для повседневного планирования.

## Anti-Corruption Layer

**Anti-Corruption Layer** (ACL) - это паттерн проектирования помогающий создать границу между новой системой и унаследованной. Через этот уровень проходят все данные, которые системы передают друг другу. ACL знает их форматы и модели данных. Он адаптирует информацию под требования получателя.

Создается с помощью паттернов **Facade** и **Adapter** и располагается в монолите.

Основные задачи ACL:
- **изоляция микросервисов от сложностей и проблем унаследованной системы** для того чтобы повысить шансы на то, что новые системы будут работать эффективно;
- **управление маршрутизацией запросов между монолитом и микросервисами**;
- **адаптация данных под требования разных систем**;
- **инкапсуляция монолитной системы**, чтобы микросервисы взаимодействовали с чистым и последовательным интерфейсом унаследованной системы, что упрощает разработку и сопровождение новых сервисов.

Принцип работы:
1. **Микросервис** взаимодействует с **монолитной системой** - он посылает запрос на **ACL**;
2. **ACL** передает запрос **адаптеру**, чтобы он перевел запрос микросервиса в формат и семантику монолитной системы;
3. **Адаптер** переводит запрос и отправляет его **монолитной системе**;
4. **Монолитная система** обрабатывает запрос и отправляет ответ **адаптеру**;
5. **Адаптер** переводит ответ в формат и семантику микросервиса, а затем передает запрос **ACL**;
6. **ACL** отправляет переведенные данные **микросервису**.

ACL используется только в процессе перехода, позволяя провести постепенную миграцию. ACL выводят из эксплуатации, когда все зависимые сервисы перенесли в архитектуру микросервисов.

Не используется когда:
- прямую интеграцию просто осуществить;
- разрабатывается краткосрочный проект или временное решение;
- критически важна производительность приложения;
- ограниченность ресурсов;
- при внедрении система станет слишком сложной.

Внедрение состоит из указанных шагов:
1. **Определение границ и зависимостей** между унаследованной системой и микросервисами - какие части унаследованной системы будут взаимодействовать с новыми сервисами и должны быть доступны и какие у них будут общие данные, процессы и функциональные возможности;
2. **Разработка интерфейса ACL**, который абстрагирует сложности унаследованной системы и должен быть чистым и четко определенным, а также согласованым с требованиями микросервисов;
3. **Внедрение ACL-компонентов**:
    - **адаптеров данных**, которые преобразуют форматы данных и обеспечивают совместимость унаследованной системы и микросервисов;
    - **шлюзов сервисов**, которые нужны для управления взаимодействием между старой системой и микросервисов - преобразованием протоколов, маршрутизацией запросов и преобразованием ответов;
    - **инкапсуляция бизнесс-логики** для того чтобы микросервисы могли взаимодействовать с упрощенным и согласованным интерфейсом.
4. **Тестирование ACL** чтобы убедиться что он правильно транслирует данные и протоколы между старой системой и новыми сервисами и не вносит значительных задержек или накладных расходов;
5. **Развертывание ACL и внедрение мониторинга**.

## Маршрутизация в микросервисах

**Маршрутизация** - это способы управления и направления потока трафика между различными частями системы.

Польза маршрутизации в период миграции:
- **безболезненное взаимодействие с пользователями** для обеспечения минимальных перебоев в работе пользователей и стабильную производительность при замене одной части системы на другую или ее обновлении;
- **непрерывность работы**, так как она позволяет старой и новой системам сосуществовать и работать одновременно;
- **инкрементное развертывание** что позволяет поддерживать поэтапное развертывание новых функций и сервисов;
- **управление рисками** за счет возможности отката или перенаправления трафика.

Основные проблемы:
- **сложность управления трафиком** из-за управления **множеством путей** трафика как к монолиту, так и к микросервисам, что повышает сложность и обеспечение **согласованности данных и состояния** как монолитного компонента, так и микросервиса, особенно при записи;
- **задержка и производительность** из-за наличия дополнительного уровня, который может стать узким местом;
- **обработка сбоев** при отказе сервисов и создания **механизмов аварийного восстановления** (fallback mechanisms) для перенаправления трафика с сервисов;
- **безопасность данных и управление доступом** между старой системой и новыми микросервисами;
- **полная видимость потока трафика и отладка проблем в гибридной среде**.

### Техники маршрутизации между монолитом и новыми сервисами

#### Обратный прокси

**Обратный прокси-сервер** (reverse proxy) - это промежуточный сервер, который ретранслирует запросы клиентов из внешней сети на один или несколько серверов внутренней сети.

Правила и условия маршрутизации определяют на основе шаблонов URL, заголовков или других атрибутов запроса, которые обозначают назначение трафика.

Имеет такие преимущества:
- **упрощенная маршрутизация**, так как логика маршрутизации централизуется, что упрощает управление и обновление в процессе миграции;
- **балансировка нагрузки** из-за распределения входящего трафика между несколькими экземплярами службы, что повышает производительность и надежность;
- **безопасность**, так как действует в виде барьера между клиентами и внутренними серверами, что обеспечивает дополнительный уровень безопасности;
- **кэширование** для того, чтобы снизить нагрузку на внутренние службы и улучшить время отклика.

#### API-шлюз

**API-шлюз** (API Gateway) - это продвинутая и многофункциональная альтернатива обратному прокси-серверу, которая обрабатывает все входящие запросы и перенаправляет их на основе заранее определенных правил (которые можно определить), управлять эндпоинтами, применять политики безопасности и преобразовывать запросы или ответы.

Имеет такие преимущества:
- **унифицированная точка входа** для всех сервисов, что упрощает взаимодействие с клиентами;
- **централизованное управление системами безопасности, аутентификации и авторизации** для того чтобы обеспечить последовательное применение политик;
- **ограничение скорости и дробление входящих запросов** для того чтобы защитить внутренние службы от перегрузки;
- **аналитика и мониторинг** для отслеживания шаблонов запросов, производительности и ошибок.

#### Service Mesh

**Service Mesh** - это выделенный инфраструктурный уровень для обработки взаимодействия между сервисами в архитектуре микросервисов. Он обеспечивает расширенную маршрутизацию, управление трафиком и возможности наблюдения.

Он предполагает, что рядом с каждым экземпляром микросервиса развертывается прокси-сервер **Sidecar** в рамках одного пода или контейнера, который управляет всеми сетевыми соединениями с микросервисом - координирует запросы к нему и от него.

## Проектирования микросервисов

Состоит из определения:
1. **Границ сервисов** - идентификации бизнес-доменов и субдоменов и обеспечения того, чтобы сервисы инкапсулировали конкретные бизнес-функции;
2. **Методов взаимодействия** между микросервисами с помощью:
    - **синхронного** взаимодействия чтобы обеспечить высокую производительность и быстрый отклик;
    - **асинхронного** взаимодействия, которое эффективнее для развязки и масштабируемости;
3. **Управления данными** которое должно обеспечивать в нескольких сервисах:
    - **согласованность данных** - чтобы изменение данных в одной системе предсказуемо влияло на другие системы;
    - **целостность данных** - поддержание корректности и надежности данных при их распределении;
    - **производительность** за счет масштабируемости, балансировки для уменьшения задержки;
    - **конкурентность** для одновременного доступа к данным и их обновления без конфликтов;
    - **доступность** для служб даже в случае сбоев.
4. **Стратегии развертывания** которые определяют, как новые версии микросервисов будут вводиться в эксплуатацию, минимизируя риски и обеспечивая непрерывность работы системы. А также совместимость новых версий микросервисов с текущими, возможность тестирования в реальной среде, механизмы для мониторинга состояния системы и быстрого отката в случае проблем;
5. **Балансировки нагрузки**, которая обеспечивает равномерное распределение трафика, для того чтобы входящие запросы равномерно распределялись между несколькими экземплярами сервиса, не позволяя какому-либо одному экземпляру стать узким местом. Способствует:
    - **повышению производительности и пропускной способности** из-за равномерного распределения запросов, чтобы каждый экземпляр службы обрабатывал управляемую нагрузку, обеспечивая более быстрое время отклика для пользователей;
    - **высокой доступности и надежности**, так как направляет трафик от отказавших или перегруженных экземпляров к исправным, что гарантирует, что приложение останется доступным, даже если некоторые экземпляры сервисов не работают или испытывают большую нагрузку;
    - **масштабируемости**, позволяя плавно добавлять новые экземпляры сервиса, что даст возможность по мере роста нагрузки подключить дополнительные экземпляры, на которые балансировщик нагрузки начнет направлять трафик, обеспечивая способность системы справляться с возросшим трафиком;
    - **устойчивости к сбоям** благодаря мониторингу состояния экземпляров сервисов, чтобы автоматически обнаруживать и удалять из пула нездоровые экземпляры, не позволяя им принимать трафик, что повышает отказоустойчивость системы, гарантируя, что сбои изолированы и не влияют на общую производительность.
6. **Устойчивости к сбоям**, которая обеспечивает проектировку микросервисов таким образом, чтобы легко справляться с отказами некоторых сервисов и не приводить к отказу всей системы благодаря внедрению механизмов повторных попыток, использованием прерывателей для предотвращения каскадных отказов и проектированию сервисов без состояний;
7. **Масштабируемости** в зависимости от нагрузки и проектированию сервисов без состояний;
8. **Безопасности** за счет внедрения сегментации сети из-за распределенной системы, которая ограничивает доступ между различными частями системы и внедрения **HTTPS** для защиты данных при передаче между микросервисами и внешними клиентами, и использование стандартов **OAuth2** / **OpenID Connect** для управления доступом и подтверждения личности пользователей и сервисов;
9. **Мониторинга и наблюдения** за состоянием и производительностью микросервисов для обеспечения надежности и доступности систем, а также агрегирование и анализ данных по всем сервисам;
10. **Хранения данных**, так как каждый микросервис может иметь уникальные требования к хранению данных и правильное разделение данных между микросервисами помогает минимизировать зависимости и улучшить управляемость системы, способствуя независимому масштабированию и развертыванию отдельных компонентов;
11. **API-менеджмента** для создания, публикации, мониторинга, управления и обеспечения безопасности интерфейсов прикладного программирования (API) в безопасной и масштабируемой среде, чтобы централизованно управлять доступом, маршрутизацией запросов, мониторингом и безопасностью API и обеспечивать балансировку нагрузки и защиту от атак. А также документирование API для того, чтобы обеспечить ясное описание функциональности и использования интерфейсов, чтобы разработчики могли быстро и правильно интегрировать API в свои приложения;
12. **Тестирования и валидации** чтобы проверять работоспособность и соответствие функциональных требований разрабатываемого продукта и убеждаться, что созданный продукт соответствует ожиданиям пользователей и бизнес-задачам;
13. **DevOps-практик** для обеспечивания быстрых итераций и непрерывных доставок, способствуя созданию гибкой среды разработки;
14. **Версионирования и совместимости** различных версий микросервисов друг с другом путем управление API и контрактами данных между сервисами, и обеспечивания обратной совместимости новых версий API с предыдущими.

## Процесс взаимодействия между микросервисами

### Синхронное взаимодействие

#### REST

**REST** (Representational State Transfer) - это архитектурный стиль, использующий стандартные методы HTTP (`GET`, `POST`, `PUT`, `DELETE`) для связи между сервисами. Он основан на связи без статических параметров и на архитектуре клиент-сервер, когда клиент отправляет запросы, а сервер отвечает соответствующими ресурсами.

**Принципы**:
- **отсутствие статуса у сервера** - когда каждый запрос от клиента к серверу должен содержать всю информацию, необходимую для понимания и обработки запроса и сервер не хранит контекст клиента между запросами;
- **унифицированный интерфейс** - согласованный способ взаимодействия с ресурсами, обычно использующий стандартные методы HTTP;
- **Resource-Based** - когда сервисы моделируются как ресурсы, идентифицируются по URL и управляются с помощью форматов (JSON, XML и т.п.);
- **архитектура клиент-сервер** - когда клиент и сервер разделены, что позволяет им развиваться независимо друг от друга;
- **кэшируемость** - так как ответы могут определять, можно ли их кэшировать для повышения производительности.

**Преимущества использования**:
- **стандартизация** - обеспечивается стандартизированный способ доступа к ресурсам, что облегчает понимание и использование разработчиками;
- **масштабируемость** - из-за отсутствие статичности, что позволяет сервисам легко масштабироваться;
- **интероперабельность** - так как взаимодействие происходит на основе HTTP, что обеспечивает совместимость различных платформ и языков;
- **отсутствие специализированных фреймворков** - так как стандартная реализация есть в большинстве современных языков программирования.

**Используется для**:
- **общедоступных API** благодаря своей простоте и широкому распространению;
- **CRUD-операции** (create, read, update, delete) из-за ресурсного подхода;
- **связи микросервисов** в сценариях, в которых сервисы должны предоставить *endpoints* для доступа к данным или работы с ними.

#### RPC

**RPC** (Удаленный вызов процедур) - это метод связи между серверами в распределенной системе, который позволяет программе вызывать функции или процедуры, находящиеся на удаленном сервере, как если бы они были локальными.

RPC абстрагирует сетевую коммуникацию, предоставляя разработчикам более простой и понятный способ взаимодействия между компонентами распределенных систем.

**Основные характеристики**:
- **прозрачность** - так как вызов удаленной функции выглядит так же, как и вызов локальной функции;
- **синхронность** - когда клиент ожидает ответа от сервера для продолжения выполнения;
- **типизация** - что позволяет проверять корректность данных на этапе компиляции.

### Асинхронное взаимодействие

#### Event-Driven Architecture

**Event-Driven Architecture** (EDA, Архитектура, управляемая событиями) - это парадигма проектирования, в которой поток программы определяется событиями, такими как действия пользователя, выходы датчиков или сообщения от других сервисов.

EDA способствует свободному соединению, масштабируемости и обработке данных в реальном времени, позволяя сервисам реагировать на события асинхронно.

**Ключевые принципы**:
- **продюсеры** генерируют события, а **консьюмеры** прослушивают и реагируют на них;
- **брокеры** являются посредниками между продюсерами и консьюмерами, обеспечивая надежную доставку событий;
- **потоки** событий непрерывны, и их можно обрабатывать в режиме реального времени.

**Преимущества архитектуры**:
- **масштабируемость** - так как сервисы могут масштабироваться независимо в зависимости от нагрузки на события;
- **разделение** - сервисы могут работать независимо друг от друга, уменьшая взаимозависимость;
- **обработка в реальном времени**, которая обеспечивает аналитику в реальном времени и быстро реагирующие системы;
- **устойчивость к сбоям** - когда сообщения могут быть поставлены в очередь, что гарантирует, что они не будут потеряны и смогут быть обработаны, когда потребитель будет доступен.

**Системы обмена сообщениями** обеспечивают асинхронную связь между сервисами, позволяя им обмениваться сообщениями через инфраструктуру обмена сообщениями. Они помогают разделять сервисы, улучшать масштабируемость и повышать отказоустойчивость, предоставляя буфер, способный справиться с переменной нагрузкой и временной недоступностью сервисов. Являются основой для EDA.

### Выбор метода взаимодействия

Осуществляется по ключевым факторам:
- **латентности** (время, необходимое для прохождения сообщения от отправителя к получателю и обратно):
    - синхронные методы для задач, где требуется немедленный ответ;
    - асинхронные методы для некритичных по времени операций, где задержка может быть терпимой или не требуется немедленного ответа на запрос.
- **консистентности данных** для обеспечения целостности данных в распределенных сервисах:
    - синхронные методы для операций, требующих немедленной согласованности;
    - асинхронные методы для сценариев, в которых допустима конечная согласованность.
- **масштабируемости** - способность справляться с растущими нагрузками путем добавления дополнительных ресурсов:
    - синхронные методы для более простых, тесно связанных взаимодействий;
    - асинхронные методы для сервисов, которые должны масштабироваться независимо друг от друга и обрабатывать всплески трафика.
- **отказоустойчивости** - способность системы продолжать работу в случае сбоя:
    - синхронные методы требуют надежной обработки ошибок и механизмов повторных попыток для достижения отказоустойчивости;
    - асинхронные методы для повышения отказоустойчивости и предотвращения потери сообщений при сбоях в работе служб.

## Работа с данными

Работа с данными должна подчиняться требованиям ACID:
- **Atomicity** - атомарность - все операции в транзакции либо завершаются успешно, либо откатываются;
- **Consistency** - целостность - любое изменение данных проходит через транзакционные контексты, которые следят за соблюдением всех ограничений;
- **Isolation** - изолированность - позволяет избежать конфликтов между параллельными транзакциями;
- **Durability** - надежность - все изменения, сделанные в рамках транзакции, применяются и сохраняются даже в случае сбоя системы.

Стратегии обеспечения согласованности данных:
- **конечная согласованность**, которая гарантирует, что при необходимом времени все реплики данных придут к одному и тому же значению. Используется в распределенных системах, где не требуется немедленная согласованность. Подходит для сценариев, в которых высокая доступность и устойчивость к разделениям более важны, чем немедленная согласованность;
- **строгая согласованность**, которая гарантирует, что все операции чтения возвращают последнюю запись. Используется когда требуется строгая точность данных. Подходит для критически важных операций, где точность данных не может быть нарушена;
- **партицирование данных**, которое подразумевает разделение большого набора данных на более мелкие и управляемые части (партиции), распределенные между несколькими узлами. Используется когда требуется сбалансировать нагрузку и повысить производительность. Подходит для крупномасштабных систем, где различные разделы могут управляться независимо друг от друга для обеспечения масштабируемости и производительности.

### Распределенные транзакции

Распределенные транзакции координируют выполнение операций в нескольких сервисах, чтобы гарантировать, что все части транзакции либо зафиксируются, либо откатятся вместе.

#### Протокол двухфазной фиксации 

**Протокол двухфазной фиксации** (2 Phase Commit, 2PC) - это подход к управлению распределенными транзакциями, которы включает в себя две фазы:
- **фаза подготовки**, когда координатор отправляет сообщение `prepare` всем участвующим сервисам с просьбой подготовиться к фиксации транзакции. На что каждый сервис отвечает голосованием (**зафиксировать** или **прервать**) в зависимости от того, сможет ли он успешно зафиксировать транзакцию;
- **фаза фиксации**, когда все сервисы голосуют за фиксацию, координатор отправляет сообщение о фиксации всем сервисам, указывая им на фиксацию транзакции. Если какая-либо служба голосует за отказ, координатор посылает сообщение об **отказе**, предписывая всем службам откатить транзакцию.

**Проблемы**:
- **блокировка** - в случае если координатор не справляется, участники могут остаться в неопределенном состоянии, ожидая решения;
- **производительность**, так как протокол может вносить задержки из-за необходимости многократных обходов между координатором и участниками.

#### Паттерн Saga

**Паттерн Saga** - это архитектурный паттерн для управления распределенными транзакциями в микросервисных системах, который обеспечивает целостность данных и позволяет управлять ошибками при выполнении долговременных бизнес-процессов, которые включают несколько микросервисов. Это решается с помощью набора локальных транзакций и компенсирующих действий. Каждая транзакцию дробиться системой на шаги, которыми занимаются разные микросервисы. В случае ошибки система активирует отмену действия, которая распространяется на все вовлеченные микросервисы.

Подходы к координации шагов:
- **оркестрацию** - которая подразумевает наличие отдельного сервиса-оркестратора, который управляет последовательностью выполнения шагов и при необходимости инициирует компенсирующие действия. Применяется когда есть:
    - **сложные бизнес-процессы** с четкой последовательности действий;
    - **потребность в централизованном управлении** потоком операций и логикой обработки ошибок;
    - **координация транзакций** с обеспечением согласованности и возможности отката;
    - **сложная бизнес-логика и управление состоянием** которые реализуются в центральном оркестраторе.
- **хореографию** - когда микросервисы взаимодействуют через события и знают что делать после выполнения своего шага, а также сами инициируют компенсирующие действия. Применяется когда есть:
    - **простые взаимодействия** и не требуется сложная координации между ними;
    - **независимые микросервисы** и изменение одного сервиса не сильно влияет на другие;
    - **в приоритете гибкость и масштабируемость в системе**. чтобы изменения в одном микросервисе не требовали изменения в других;
    - **событийно-ориентированная архитектура**.

Требования ACID соблюдаются в:
- **атомарности** - так как транзакции разделяются на последовательные шаги, где каждый шаг - это локальная транзакция в отдельном микросервисе и атомарность достигается за счет независимого выполнения каждого шага и применения компенсирующих действий для отката изменений;
- **целостности** - которая обеспечивается через компенсирующие действия, которые откатывают предыдущие шаги в случае ошибки, так как микросервисы координируют между собой состояние транзакции, что иногда требует дополнительной логики;
- **изолированности** - только в конце транзакции, так как микросервисы работают независимо и пока все шаги Saga не завершатся, система может столкнуться с временной неконсистентностью данных;
- **надежности** - которая зависит от отдельных микросервисов и их способности сохранять состояние и поэтому компенсирующие действия должны быть надежными и обеспечивать сохранение состояния даже при сбоях.

**Компенсационные транзакции** - это действия, которые откатывают результаты уже выполненных шагов, если на любом из следующих шагов возникла ошибка.

**Преимущества**:
- **неблокируемость**, поскольку сервисы не блокируются из-за того, что каждый шаг независим и может быть отменен при необходимости;
- **масштабируемость и устойчивость к сбоям**.

**Процесс внедрения**:
1. **Анализ бизнес-процесса** и разделение его на последовательные шаги, которые будет выполнять отдельный микросервис. Для каждого шага определяется **основное действие** (do) и **компенсирующее действие** (undo), которое нужно выполнить в случае ошибки;
2. **Проектирование API у микросервисов** для выполнения действий и компенсирующих действий. Каждая операция для всех действий и компенсирующих действий должна быть **идемпотентной**, для этого используются уникальные идентификаторы транзакций и проверяется состояние перед выполнением операции, чтобы избежать повторного выполнения;
3. **Обеспечение хранения состояния** своей части транзакции в каждом микросервисе. Состояние должно включать уникальный идентификатор транзакции и текущий статус операции, чтобы избежать повторения уже совершенных действий. И выбора подхода к координации шагов;
4. **Реализация действий и компенсирующие действий** в каждом микросервисе, которые должны быть **идемпотентны**;
5. **Добавление логирования** для всех действий и компенсирующих действий, которые должны включать информацию о транзакциях, их статусе и любых ошибках. А также **настройка мониторинга** микросервисов (оркестратора);
6. **Тестирование** основных действий и компенсирующие действий в каждом микросервисе, а также цельной транзакции.

## Стратегии развертывания

### Обновление на месте

**Обновление на месте** - это когда новая версия приложения заменяет старую версию на той же инфраструктуре. Часто это делается путем остановки службы, развертывания нового кода и перезапуска службы.

### Сине-зеленые релизы (Blue-Green)

**Сине-зеленые релизы** - это когда поддерживаются два идентичных окружения - синее и зеленое. Пока одно работает и обслуживает продакшн, другое используется для развертывания и тестирования новой версии. Затем, когда новая версия прошла тестирование в новом окружении, трафик переключается на него. Так как старое теперь простаивает, то может быть использована для следующего обновления. И так далее.

**Основное преимущество**: отсутствие простоев и простой откат, так как при обнаружении проблем трафик можно быстро переключить на исходную среду.

**Основной недостаток**: нужно поддерживать две идентичные среды, что может быть дорогостоящим и ресурсоемким.

### Канареечные релизы (Canary)

**Канареечные релизы** - это когда при обновления новая версия разворачивается на каком-то количестве серверов (**канареечные серверы**) и затем туда направляется небольшой процент трафика. Развертывание отслеживается на предмет ошибок и, если проблем не обнаружено, туда направляется все больше трафика. В конце концов новая версия разворачивается на всех серверах.

**Основное преимущество**: позволяет проводить мониторинг и тестирование в реальных условиях с минимальным риском и ограничивает влияние потенциальных проблем небольшой базой пользователей.

**Основной недостаток**: требуются сложные механизмы маршрутизации и мониторинга трафика.

### Скользящие релизы (Rolling)

**Скользящие релизы** - это когда при релизе экземпляры приложения постепенно обновляются по одному или небольшими партиями без простоев, что обеспечивает постоянное обслуживание трафика одними экземплярами, в то время как другие находятся в процессе обновления.

**Основное преимущество**: обеспечивается постоянная доступность сервиса и снижается риск сбоев за счет обновления небольшими порциями.

**Основной недостаток**: необходимость тщательной координации, чтобы обеспечить бесперебойное обновление и механизмы отката.

Масштабирование решения
=======================

**Масштабирование решения** - это адаптация программного обеспечения к увеличению нагрузки или требований с сохранением высокой производительности и доступности.

**Вертикальное масштабирование** - это добавление ресурсов (оперативной памяти (RAM), мощности процессора (CPU), объема жесткого диска (HDD) и т.п.) к одному узлу на сервере. Имеет физические ограничения и часто стоит дорого.

**Горизонтальное масштабирование** - это добавление новых узлов в систему, что позволяет распределить нагрузку между ними. Это обеспечивает практически неограниченный рост и лучшую отказоустойчивость, но требует более сложной настройки и управления.

## Репликация

**Репликация** - это создание и поддержание копий базы данных на нескольких серверах, что обеспечивает высокую доступность, повышенную производительность и отказоустойчивость.

**Преимущества**:
- **высокая доступность данных**, так как данные дублируются на нескольких серверах, что позволяет обеспечить непрерывность работы системы;
- **высокая производительность системы** из-за распределения нагрузки на чтение между несколькими узлами, что снижает нагрузку на основной сервер и улучшает производительность;
- **отказоустойчивость**, так как при сбое одного из серверов данные остаются доступными на других репликах, что минимизирует риск потери данных и простоев;
- **гибкость в распределении нагрузки**, так как запросы на чтение отправляются в улзы, которые ближе всего к пользователю географически, что снижает задержки и повышает скорость доступа к данным.

**Ограничения**:
- **сложности с консистентностью данных** (устареванию) на узлах в случае задержек репликации, что требует дополнительных механизмов синхронизации и управления конфликтами;
- **ресурсозатратность**, поскольку поддержание нескольких копий данных требует дополнительных вычислительных и дисковых ресурсов;
- **сложность управления** системой с несколькими репликами усложняется необходимостью мониторинга состояния каждой реплики, обеспечения их синхронизации и обработки сбоев.

### Репликация master-slave

**Репликация master-slave** устраняет узкие места в производительности и обеспечивает доступность данных в условиях увеличения пользовательского трафика или сбоев оборудования.

Состоит из:
- **главного, первичного узла** (мастера, master) - ответственного за обработку всех операций записи и управление данными;
- **подчиненого, вторичного узла** (реплики, слейва, slave) - который пассивно реплицируешего данные от главного узла и обслуживает запросы на чтение в случае применения паттерна read-replica. Их может быть несколько.

Когда на главном узле происходит операция записи, он регистрирует изменения в журнале транзакций. Затем подчиненные узлы извлекают эти журналы и применяют изменения к своим копиям данных. В зависимости от требований к согласованности, ведомые узлы могут:
- приостановить свою работу до получения обновлений от главного;
- продолжать обслуживать возможно устаревшие данные, одновременно применяя последние изменения в фоновом режиме.

В случае *потери* мастера, следующим мастером становится кто-то из подчиненных узлов, в зависимости от настройки.

#### Паттерн read-replica

**Паттерн read-replica** заключается в чтении только с подчиненных узлов, а записи только в главный узел.

При применении этого паттерна существует проблема - **задержка репликации**, когда данные в подчиненных могут отставать от главного узла. Для решения используется:
- считывания с учетом задержки отправляются в главный узел;
- чтения, за которыми сразу следуют записи, направляются в главный узел;
- проверка совпадения данных в главном узле и подчиненным и при не совпадении чтением из главного.

### Репликация multi-master

**Репликация multi-master** - это репликация master-slave только когда несколько узлов выполняют роль главных узлов со своими подчиненными узлами. Данные синхронизируются между узлами, а запись может происходить на любом из главных узлов. В результате создается несколько копий данных. Система решает проблему конфликтов между одновременными изменениями.

**Преимущества**:
- в случае сбоя одного главного узла другой главный узел может обновить и вставить данные;
- главные узлы находятся в разных местах, поэтому вероятность сбоя всех главных узлов крайне мала;
- обновления данных возможны на нескольких серверах;
- приложению не нужно направлять трафик только на один главный узел.

**Недостатки**:
- сложность настройки и поддержки;
- потенциальные задержки в данных.

## Кэширование

**Кэширование** снижает нагрузку при большом количестве операций чтения одинаковых данных.

**Принцип работы**:
1. Приложение проверяет наличие нужных данных в кэше;
2. Если данных в кэше нет, то запрос направляется в хранилище;
3. На обратном пути данные передаются в кэш, а запрос возвращается пользователю.

**Используется**:
- при высокой нагрузке на чтение для текущих ресурсов;
- при наличии редко изменяемой информации, которую необходимо часто получать из хранилища.

**Основная сложность**: данными в кэше нужно управлять, чтобы поддерживать их согласованность.

### Распределенный кэш

**Распределенный кэш** - это система, в которой данные хранятся на нескольких узлах кластера и в нескольких кластерах в разных центрах обработки данных по всему миру.

Система распределенного кэша объединяет оперативную память нескольких сетевых компьютеров в единое хранилище данных в оперативной памяти, которое используется в качестве кэша для быстрого доступа к данным. Она позволяет постепенно расширять и масштабировать систему, добавляя новые компьютеры в кластер.

### Виды кэширования

Виды кэширования:
- **FIFO** - если искомый элемент не находится в кэше, он вставляется в хвост очереди. Если нужно освободить место, удаляются элементы из головы очереди. Таким образом вытесняется элемент, находящийся в кэше дольше всех.
- **LRU** - новый элемент вставляется в голову списка. При запроса из кэша элемент перемещается в голову списка. Если нужно освободить место, вытесняется элемент из хвоста списка.
- **MRU** - последний использованный вылетает из кэша.
- **LFU** - каждый элемент имеет счетчик обращений. Новый элемент вставляется в кэш со значением счетчика равным 1. При попадании в кэш счетчик найденного элемента увеличивается на 1. Если нужно освободить место, нужно найти элемент с самым маленьким значением счетчика.
- **SNLRU** (сегментированный LRU) - это N кэшей LRU. Новый элемент вставляется в нулевой LRU кэш. При попадании в кэш элемент перемещается в следующий LRU кэш, либо на MRU (Most Recently Used) позицию последнего LRU кэша, если выше уже идти некуда. При вытеснении элемента из k-го LRU кэша он перемещается в k-1 LRU кэш. По достижению нулевого LRU кэша элемент удаляется.
- **2Q** - кэш разделяется на три части:
    - **In** - FIFO кэш, в который попадают все новые элементы, запрошенные отсюда элементы никуда не перемещаются;
    - **Out** - FIFO кэш, в который попадают элементы, вытесненные из **In**. При этом этот кэш хранит ключ и не хранит значение, поэтому его можно сделать достаточно большим;
    - **Main** - главный LRU кэш, в который попадают новые элементы запрошенные из **Out**, в котором они удаляются. При вытеснении элемента из главного кэша он удаляется.
- **MQ** - сегментированный LRU в котором запоминается позиция с которой элемент вылетел - и при повторном запросе - возвращается туда, где был, если не вылетел из очереди запомненных позиций.

## Шардирование и партиционирование

**Партиционирование** (секционирование) - метод разделения больших объемов данных на отдельные сегменты. **Шардирование** - это частный случай партиционирования.

**Вертикальное партиционирование** - это метод разделения одной большой таблицы на несколько меньших, которые физически хранятся отдельно и которые по структуре отличаются от исходной таблицы. Оно позволяет повысить производительность и доступность данных, поскольку операции выполняются над меньшим количеством данных.

**Горизонтальное партиционирование** (шардирование, сегментирование) - распределение данных по нескольким базам, чаще всего на отдельных физических серверах. Оно предполагает разделение данных на группы по определенным **критериям** и в результате разделения данных каждый **сегмент** (шард) включает одни и те же столбцы, но разные строки информации.

Преимущества горизонтального партиционирование:
- **преодолевание технических ограничений**, так как позволяет распределить данные по разным серверам;
- **повышение надежности**, так как шарды базы данных расположены на разных серверах, отказ одного из них не приведет к полной остановке работы;
- **ускорение доступа к данным с простыми запросами** из-за распредения нагрузки и увеличения объемов и скорости обработки данных.

Ограничения горизонтального партиционирование:
- **сложность реализации**;
- **риск снижения эффективности разработки** из-за необходимости управлять данными из нескольких сегментов вместо единой точки;
- **неравномерность загрузки серверов** из-за несбалансированности данных, когда одни серверы оказываются загружены больше, чем другие, что потребует повторного сегментирования;
- **снижение скорости обработки сложных запросов**, требующих обращения к нескольким шардам одновременно, что может привести к потере производительности и замедлению процесса получения данных по сравнению с обращением к одной таблице.

### Методы шардирования

**Хэшированное шардирование** (key based sharding) - это разделение данных на шарды на основе хэш-функции, которая принимает входные данные и возвращает хэш-значение, которое определяет, в какой шард попадет каждая запись данных.

Особенности:
- риск потери данных: **низкий**, так как отсутствует единая точка отказа;
- распределение данных: **равномерное**;
- поиск данных: **средний**;
- реализуемость: **легкая**;
- масштабируемость хранилища: **высокая**;
- геораспределение данных: **отсутствует**.

Подходит для равномерного распределения данных.

**Диапазонное шардирование** (range based sharding) - разделение данных на шарды на основе диапазона значений (chunk). Значения разделяются не с помощью функции, а по ключу или другим атрибутам. Каждому фрагменту присваивается диапазон на основе значений ключа сегментирования. Ключи сегментов, чьи значения близки друг к другу, чаще всего оказываются в одном диапазоне. Это упрощает выполнение целевых операций.

Особенности:
- риск потери данных: **низкий**;
- распределение данных: **неравномерное**;
- поиск данных: **легкий**;
- реализуемость: **легкая**;
- масштабируемость хранилища: **высокая**;
- геораспределение данных: **отсутствует**.

Подходит для данных временных рядов или последовательных данных (журналы, события с временными метками, цены на товары и т. д.).

**Динамическое шардирование** (dynamic sharding) - автоматическое масштабирование хранилища в зависимости от текущей производительности и объема данных. Оно очень гибкое, но требует сложной балансировки нагрузки, надежного мониторинга и тщательно продуманной архитектуры базы данных.

Для определения местоположения записей используется **внешний поисковый сервис**, что помогает решать проблемы, возникающие при динамическом сегментировании. Внешний поиск предоставляет полную информацию о том, в каком сегменте находятся данные, что позволяет перемещать пользователей по отдельности, а не большими группами, из одного сегмента в другой. Это помогает снизить нагрузку на перегруженные сегменты. При этом поисковый сервис становится единственным местом взаимодействия с системой и потенциальным источником сбоев.

Особенности:
- риск потери данных: **высокий**;
- распределение данных: **неравномерное**;
- поиск данных: **сложный**;
- реализуемость: **сложная**;
- масштабируемость хранилища: **автоматическая**;
- геораспределение данных: **возможно**.

**Геошардинг** (geo sharding) - это хранение в разных сегментах информации, относящейся к определенной географической зоне. Его можно комбинировать с другими методами шардирования, если это необходимо.

Особенности:
- риск потери данных: **низкий**;
- распределение данных: **неравномерное**;
- поиск данных: **легкий**;
- реализуемость: **легкая**;
- масштабируемость хранилища: **средняя**;
- геораспределение данных: **реализована**.

Подходит для сервисов, которым важна локальность данных (для сетей доставки контента и мобильных приложений с учетом геолокации).

### Способы реализации шардирования

Основные способы реализации шардирование:
- **средствами базы данных**, которые могут автоматически распределять данные между своими экземплярами, что задается через конфигурацию баз данных;
- **с использованием надстроек к базе данных** - сторонние утилиты, которые выполняют шардирование;
- **с применением клиентских средств**, когда экземпляры базы данных не знают о существовании друг друга, а шардированием управляет сервис.

## Горизонтальное масштабирование приложения

### Способы сохранения состояний приложения

**Stateful** (с сохранением состояния) - подход, при котором система сохраняет информацию о предыдущих состояниях или взаимодействиях с клиентами. Применяется в ситуациях, когда экземпляров (инстансов) приложения несколько, но пользователю нужно всегда попадать на сервер, который владеет конкретным закрепленным за ним состоянием.

Приложения с состояниями обычно масштабируют не напрямую, а через масштабирование базы данных, распределенное кэширование и разделение на более независимые микросервисы, каждый из которых работает только над отдельными частями процесса независимо.

**Stateless** (без сохранения состояния) - подход, при котором архитектура приложения не сохраняет информацию о предыдущих состояниях или сеансах где-то отдельно от остальных сервисов. Каждый запрос рассматривается как изолированное взаимодействие.

Масштабируется горизонтально с помощью балансировщика нагрузки.

### Балансировщик нагрузки

**Сервис балансировки нагрузки** - это инструмент для распределения запросов между серверами внутри кластера.

Основные решаемые задачи:
- **обеспечивание непрерывной работы приложения** из-за автоматического направления трафика с проблемных серверов на здоровые, что позволит избежать простоя в работе приложения;
- **обеспечивание горизонтального масштабирования** для возможности добавления новых экземпляров приложения и равномерного распределения нагрузки между несколькими экземплярами приложения;
- **повышение безопасности** из-за анализа трафика, фильтрования запросов, а также направление их через брандмауэры и другие защитные механизмы.

Виды по устройству:
- **программные** - это сервисы, которые обычно работают на отдельном сервере;
- **виртуальные** - это решение работает на виртуальной машине (VM) или как экземпляр программного обеспечения в виртуализированной среде;
- **аппаратные** - это непосредственно физические устройства, работающие на 4 и 7 уровнях модели OSI, которые способны обрабатывать все виды трафика: HTTP, HTTPS, TCP и UDP.

Виды по функциям:
- **на 4, транспортном уровне** - когда балансировщик быстрее обрабатывает запросы, поскольку не анализирует содержимое пакетов и имеет возможность работать с адресами серверов. Особенности:
    - использует протоколы TCP и UDP;
    - распределяет трафик, опираясь на IP-адреса и номера портов;
    - может применять базовое преобразование сетевых адресов (NAT), скрывая таким образом адреса серверов.
- **на 7, уровне приложений** - когда балансировщик маршрутизирует контент с учетом содержимого и позволяет принимать сложные решения о маршрутизации, используя данные, специфические для конкретного приложения. Особенности:
    - работает на уровне приложений с протоколами HTTP и HTTPS;
    - способен закрывать SSL-соединения.

#### Стратегии балансировки нагрузки

##### Round Robin

**Round Robin** - эта стратегия последовательно распределяет запросы между доступными экземплярами. Каждый экземпляр получает равную долю запросов в круговом порядке.

Применяется в системах, где все экземпляры имеют схожие характеристики мощности и производительности.

##### Least

Семейство стратегий особенность которых - это направлять запросы к экземплярам, по **особому критерию**, что помогает распределить нагрузку более равномерно, особенно когда есть экземпляры с разной производительностью. Бывают:
- **Least Connections** - когда критерий это наименьшее количество активных соединений;
- **Least Response Time** - когда критерий это наименьшее среднее время обработки ответа;
- **Least Bandwidth** - когда критерий это наименьший трафик.

Применяется в системах, где экземпляры могут обрабатывать запросы разной сложности и продолжительности.

##### IP Hash (Sticky sessions)

**IP Hash** - эта стратегия использует хэш IP-адреса клиента, чтобы определить, какой экземпляр будет обрабатывать запрос, что гарантирует, что запросы от одного и того же клиента будут последовательно направляться к одному и тому же экземпляру.

Применяется в системах, в которых требуется сохранение сеанса (для продолжительных пользовательских сеансов в сервисе с состоянием).

##### Weighted Round Robin

**Weighted Round Robin** - эта стратегия аналогична стратегии **Round Rrobin**, но с весами, присваиваемыми каждому экземпляру на основе его возможностей или характеристик производительности. Экземпляры с более высокими весами получают больше запросов.

Применяется в системах, где некоторые экземпляры более мощные и могут обрабатывать большую долю нагрузки.

##### Случайное распределение

**Случайное распределение** - эта стратегия случайным образом направляет запросы к экземплярам.

Применяется в системах, с равномерно распределенными экземплярами и когда другие стратегии могут не дать значительных преимуществ.

#### Настройка балансировщика нагрузки

Реализуются направлением всех запросов в **API Gateway**, который обращаясь к **Service Registry** получает адреса микросервисов, которые в нем регистрируются при создании, а затем направляет по полученным адресам запросы в микросервисы.

##### Паттерн API Gateway

**Паттерн API Gateway** - это единая точка входа для клиентских приложений, которая регламентирует коммуникации между клиентом и сервисами, убирая прямую привязку сервисов к клиентам, абстрагирует сервисы от клиентов.

Кроме основных функций имеет дополнительную функциональность: аутентификацию, походы в кэш, роутинг, логирование и другие функции и инструменты.

##### Паттерн Service Discovery

**Паттерн Service Discovery** - это паттерн, который облегчает коммуникацию между приложениями, даже если меняется количество их инстансов или сетевое расположение.

В основе лежит **Service Registry** - реестр (маленькая база данных), в котором хранится метаинформация о микросервисах, их экземплярах и сетевом расположении.

## Гибридная архитектура

**Гибридная архитектура** - это когда часть архитектуры лежит в публичном облаке, а часть внутри компании - либо тоже в облаке, но частном, либо просто на "железе".

Преимущества:
- **гибкость в поддержке**, так как доступ к данным возможен в любое время из любой точки мира и можно быстро заказать нужные ресурсы;
- **сокращение расходов**, которое происходит благодаря экономии на капитальных вложениях в расширение инфраструктуры;
- **улучшение масштабируемости** из-за использования ресурсов облачного провайдера, что позволяет адаптироваться к взлетам и падениям нагрузки;
- **быстрый выход на рынок**, который увеличивается за счет повышения производительности IT и гибкости;
- **непрерывность бизнеса** благодаря тому что гарантируется созданием резервных копий критически важных данных и масштабированием в случае увеличения спроса;
- **сохраняется безопасность** благодаря контролю над данными и ограничению доступа;
- **оптимизация скорости и увеличение отказоустойчивости за счет увеличения географии**, так как облачная инфраструктура, как правило, находится в разных ЦОДах и в разных регионах, что облегчает доступ к данным пользователям из определенных близких к этим ЦОДам регионам — получается что-то вроде геошардирования. В случае аварии в каком-то регионе остальные продолжают работать.

Недостатки:
- **сложность интеграции** внутренней инфраструктуры и публичного облака, которая требует сложной настройки мониторинга и инструментов управления инфраструктурой;
- **недостаточная безопасность** из-за строгих требований к безопасности, которые не допускают хранения многих данных в публичном облаке.

### Распределенное облачное кэширование

Преимущества:
- **высокая доступность данных** (high availability) благодаря репликации данных и механизмам аварийного переключения, так как даже если один узел выйдет из строя, другие узлы смогут взять на себя его функции без потери данных;
- **высокая скорость работы и производительности приложений** за счет хранения часто используемых данных в памяти на нескольких серверах, расположенных близко к пользователям;
- **проще масштабирование** из-за того, что легко добавлять новые узлы кэша по мере увеличения нагрузки;
- **ниже затраты** за счет снижения нагрузки на основные базы данных и оптимизации использования ресурсов, так как базы данных в обслуживании и настройке сильно дороже кэширования.

Ограничения:
- **зависимость от сети**, так как для эффективной работы необходимо надежное и быстрое сетевое соединение между серверами кэша и клиентами - облаком и локальной инфраструктурой;
- **сложность настройки и управления**, так как необходимо умение настраивать балансировку нагрузки, репликацию данных и механизмы аварийного переключения;
- **меньшая безопасность данных** из-за того что все, что в облаке, в большей опасности, чем внутри локального контура. Данные, хранящиеся в кэше, могут быть уязвимы для атак, если не приняты надлежащие меры безопасности;
- **риск потери данных** в случае сбоя в работе одного из узлов кэша данные, хранящиеся на этом узле, могут быть потеряны. Репликация данных помогает снизить этот риск, но не устраняет его полностью;
- **необходимость обучения персонала**, чтобы эффективно управлять системой и минимизировать риски;
- **влияние на производительность** из-за дополнительной нагрузки на сеть и сервера;
- **сложности интеграции** с существующими системами, так как требует тщательного планирования и тестирования.

### Content Delivery Network

**Content Delivery Network** (CDN) - это распределенные узлы хранения и доставки информации. Сервис представляет собой систему, которая в ответ на запросы от клиента запрашивает, получает и кэширует данные от источника и отдает их клиенту. Использование CDN значительно снижает нагрузку на источники хранения информации в интернете и ускоряет ее доставку пользователю.

Когда пользователь заходит на сайт, запрос направляется к ближайшему CDN-серверу. Если запрашиваемая информация кэширована на нем, данные сразу отдаются пользователю. Если данные запрашиваются впервые или они устарели, CDN-сервер сначала загружает их с сервера-источника, а затем отдает клиенту.

Преимущества:
- **улучшает SEO**, поскольку сайты загружаются быстрее, что улучшает их видимость в поисковых системах;
- **позволяет избежать дополнительных расходов на инфраструктуру**, так как не требуется покупать новое оборудование или увеличивать мощность сервера-источника;
- **повышает доступность сайта** за счет резервирования серверов друг другом, что гарантирует непрерывность работы сайта;
- **открывает доступ к подробной статистике о трафике** в реальном времени;
- **делает сайт доступным из любой точки мира** благодаря глобальному покрытию CDN;
- **снижает нагрузку на сервер-источник**.

Ограничения:
- **проблемы с динамическим контентом** из-за того, что он должен обрабатываться на сервере источнике;
- **задержки при обновлении контента** после обновления контента на основном сервере прежде чем изменения отобразятся на серверах CDN, что временно 
замедлит доступ к новому контенту;
- **блокировка по IP-адресам** что может привести к недоступности множества сайтов;
- **зависимость от CDN-провайдера**, так как технические проблемы у него могут повлиять на доступность сайта.

#### Методы разделения данных на основе DNS

**GeoDNS** (solitary traffic directors, global traffic directors) - это метод географических доменных имен, который использует алгоритм определения геокоординат по IP-адресу пользователя. Клиент отправляет запрос, DNS-сервер определяет местоположение пользователя по IP-адресу и находит ближайшую **точку присутствия** (пограничный узел, Point of presence, PoP) - базовый компонент CDN, где находятся копии или кэшированные версии контента, полученного от основного источника. Их количество и географическое расположение влияет на эффективность использования CDN. Чем ближе они к пользователям интернет-ресурса, тем быстрее доставляется им контент. Чем больше их количество, тем меньше нагрузка на исходный сервер.

GeoDNS позволяет:
- оптимизировать трафик и обеспечить надежную балансировку нагрузки;
- блокировать посетителей веб-сайта по странам;
- выдавать контент адресно в зависимости от геоположения посетителя.

**Anycast** - это метод сетевой адресации и маршрутизации, при котором один IP-адрес присваивается нескольким серверам в сети, которые при этом находятся в разных точках присутствия. В зависимости от местоположения источника запросов данные отправляются на ближайший сервер, что позволяет уменьшить количество сетевых переходов и задержку в передаче данных. Запрос DNS-клиента будет отправляться от одной точки присутствия к другой, пока не достигнет первого авторитетного сервера имен.
